# Backend environment example
# Copy this file to .env in the backend folder and fill in real values.

# ===== LLM / DeepSeek configuration =====
# Required: DeepSeek API key (or compatible OpenAI-style endpoint)
DEEPSEEK_API_KEY=sk-your-deepseek-key-here

# Optional: model + base URL (defaults shown)
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# High-level model selector (currently expects DeepSeek)
MODEL_TYPE=deepseek

# ===== Server configuration =====
HOST=0.0.0.0
PORT=8000

# ===== Data / storage paths =====
# Path to the text version of the Constitution
CONSTITUTION_PATH=./data/indian_constitution.txt

# Where to store the FAISS index
STORAGE_DIR=./storage

# Where to store uploaded documents (if/when uploads are enabled)
UPLOAD_FOLDER=./uploads

# ===== Embeddings / indexing configuration (advanced) =====
# HuggingFace embeddings model used to build the FAISS index
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking parameters for text splitting
CHUNK_SIZE=1800
CHUNK_OVERLAP=200

# ===== Optional alternative providers (not required by default) =====
# Uncomment and configure if you later extend llm.py to use them.
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini
# GEMINI_API_KEY=
# GEMINI_MODEL=gemini-1.5-flash
